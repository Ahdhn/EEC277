\section{Part B}
%=========================Intro====================================%
So far the characterization of the graphics card performance was in terms of the speed of operations. Now we turn to characterize the quality, specifically the arithmetic precision. This is considered a crucial since the speed render irrelevant if the results are not accurate. Even under the IEEE 754 Standards, identical operations could produce different results when operated on two different machines (e.g. floating point addition is not associative). 

In this section, we start by quantifying the error of the basic arithmetic operations offered by OpenGL. We compare GPU's results with the CPU to measure the error. We also try to discover a precision-related undocumented features; how rounding is implemented in our graphic card. 

%=========================Arithmetic Opt====================================%
\subsection{Arithmetic Operations Accuracy:}
Here we test a range of basic arithmetic operation offered by OpenGL and GLSL. Take the CPU results as our datum and the absolute error between the GPU's results and CPU's results represents the errors. The rationale behind this method is that both CPU and GPU are compliant with IEEE 754 Standard. This is not absolutly true if we are conducted a series of computation. For example, performing dot product between two vectors could be more accurate on GPU than on CPU \cite{whitehead2011precision} since on the CPU we would have to do each multiply-add as two separate instruction while GPU is 


%=========================Rounding====================================%
\subsection{Rounding}



